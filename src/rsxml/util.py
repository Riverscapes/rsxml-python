"""Utility functions for file and directory operations, formatting, and metadata parsing.

This module provides helper functions for:
- Batch processing of iterables
- Safe file and directory removal
- File comparison using size and MD5 hash
- Safe recursive directory creation
- Formatting byte sizes
- Calculating object memory size
- Formatting durations in a human-readable way
- Parsing metadata from strings

Logging is used for error handling and debugging.
"""

import gc
import hashlib
import math
import os
import shutil
import sys
from pathlib import Path

from rsxml.logging.logger import Logger

# Set if this environment variable is set don't show any UI
NO_UI = os.environ.get("NO_UI") is not None


def batch(iterable, num=1):
    """Split a list into a list of regularly-sized lists of size n

    Args:
        iterable ([type]): [description]
        n (int, optional): [description]. Defaults to 1.

    Yields:
        [type]: [description]
    """
    length = len(iterable)
    for ndx in range(0, length, num):
        yield iterable[ndx: min(ndx + num, length)]


def safe_remove_file(file_path):
    """Remove a file without throwing an error

    Args:
        file_path ([type]): [description]
    """
    log = Logger("safe_remove_file")
    try:
        if not os.path.isfile(file_path):
            log.warning(f"File not found: {file_path}")
        os.remove(file_path)
        log.debug(f"File removed: {file_path}")
    except Exception as err:
        log.error(str(err))


def file_compare(file_a, file_b, md5=True):
    """Do a file comparison, starting with file size and finishing with md5

    Args:
        file_a ([type]): [description]
        file_b ([type]): [description]

    Returns:
        [type]: [description]
    """
    log = Logger("file_compare")
    log.debug("Comparing: {} {}".format(file_a, file_b))
    try:
        # If the file sizes aren't the same then there's
        # no reason to do anything more
        a_stats = os.stat(file_a)
        b_stats = os.stat(file_b)
        if a_stats.st_size != b_stats.st_size:
            log.debug("Files are NOT the same size: {:,} vs. {:,}")
            return False

        # If we want this to be a quick-compare and not do MD5 then we just
        # do the file size and leave it at that
        if not md5:
            return True

        with open(file_a, "rb") as afile:
            hasher1 = hashlib.md5()
            buf1 = afile.read()
            hasher1.update(buf1)
            md5_a = str(hasher1.hexdigest())

        with open(file_b, "rb") as bfile:
            hasher2 = hashlib.md5()
            buf1 = bfile.read()
            hasher2.update(buf1)
            md5_b = str(hasher2.hexdigest())

        # Compare md5
        if md5_a == md5_b:
            log.debug("File MD5 hashes match")
            return True
        else:
            log.debug("File MD5 hashes DO NOT match")
            return False
    except Exception as err:
        log.error(f"Error comparing files: {err}")
        return False


def safe_remove_dir(dir_path):
    """Remove a directory without throwing an error

    Args:
        file_path ([type]): [description]
    """
    log = Logger("safe_remove_dir")
    try:
        shutil.rmtree(dir_path, ignore_errors=True)
        log.debug(f"Directory removed: {dir_path}")
    except Exception as err:
        log.error(f"Error removing tree: {err}")
        return False


def safe_makedirs(dir_to_create: str | Path):
    """safely, recursively make a directory with logging.

    Includes a safety check to prevent creating directories at the root level or with very short names,
    which helps avoid accidental filesystem clutter or modification of critical paths.

    If dir_to_create is a Path object, it is resolved to absolute path before checking.
    If dir_to_create is a string, it is checked as-is (strict).

    Valid paths:
    - "C:\\Users\\User\\Documents\\Project"
    - "/home/user/project/data"
    - Path("logs") (resolves to safe absolute path)

    Invalid paths (Too short or too shallow):
    - "C:\\a"
    - "/a"
    - "logs" (as string)

    Arguments:
        dir_to_create (str or Path): the directory to create
    """
    log = Logger("MakeDir")

    if isinstance(dir_to_create, Path):
        path_str = str(dir_to_create.resolve())
    else:
        path_str = str(dir_to_create)

    # Safety check on path lengths - prevents accidental root/shallow folder creation
    # Check 1: Length must be at least 5 characters
    # Check 2: Must have more than 2 components (e.g. "a/b" is 2 components. "C:\a" is 2 components)
    if len(path_str) < 5 or len(path_str.split(os.sep)) <= 2:
        raise Exception(f"Invalid path: {dir_to_create}")

    path_to_create = Path(dir_to_create)
    try:
        if not path_to_create.exists():
            log.info(f"Folder not found. Creating: {path_to_create}")
        path_to_create.mkdir(parents=True, exist_ok=True)
    except FileExistsError as exc:
        # pathlib raises FileExistsError if a file exists with the same name
        if path_to_create.is_file():
            raise FileExistsError(f"Can't create directory if there is a file of the same name: {dir_to_create}") from exc
        raise
    except Exception as err:
        log.error(f"Could not create folder: {dir_to_create}")
        raise err


def sizeof_fmt(num, suffix="B"):
    """Format bytesize properly

    Arguments:
        num {[type]} -- Size

    Keyword Arguments:
        suffix {str} -- [description] (default: {'B'})

    Returns:
        [type] -- [description]
    """
    for unit in ["", "K", "M", "G", "T", "P", "E", "Z"]:
        if abs(num) <= 1000.0:
            return f"{num:3.1f} {unit}{suffix}"
        num /= 1000.0
    return f"{num:.1f} Yi{suffix}"


def get_obj_size(obj):
    """Generic function to get the byte-size of a variable

    Arguments:
        obj {[type]} -- [description]

    Returns:
        [type] -- [description]
    """
    marked = {id(obj)}
    obj_q = [obj]
    osize = 0

    while obj_q:
        osize += sum(map(sys.getsizeof, obj_q))

        # Lookup all the object referred to by the object in obj_q.
        # See: https://docs.python.org/3.7/library/gc.html#gc.get_referents
        all_refr = ((id(o), o) for o in gc.get_referents(*obj_q))

        # Filter object that are already marked.
        # Using dict notation will prevent repeated objects.
        new_refr = {o_id: o for o_id, o in all_refr if o_id not in marked and not isinstance(o, type)}

        # The new obj_q will be the ones that were not marked,
        # and we will update marked with their ids so we will
        # not traverse them again.
        obj_q = new_refr.values()
        marked.update(new_refr.keys())

    return osize


def pretty_duration(time_s=False):
    """
    Get a datetime object or a int() Epoch timestamp and return a
    pretty string like 'an hour ago', 'Yesterday', '3 months ago',
    'just now', etc
    """
    if not time_s >= 0:
        return "???"
    seconds = math.floor(time_s % 60)
    minutes = math.floor(time_s / 60) % 60
    hours = math.floor(time_s / 3600) % 24
    if time_s < 60:
        return f"{seconds:.1f} seconds".format()
    elif time_s < 3600:
        return f"{minutes}:{seconds:02} minutes"
    elif time_s < 86400:
        return f"{hours}:{minutes:02} hours"
    else:
        days = math.floor(time_s / 86400)
        return f"{days} days, {hours}:{minutes:02} hours"


def parse_metadata(arg_string):
    """_summary_

    Args:
        arg_string (_type_): _description_

    Raises:
        Exception: _description_
        Exception: _description_
        Exception: _description_
        Exception: _description_

    Returns:
        _type_: _description_
    """
    meta = {}
    try:
        if arg_string:
            for kvp in arg_string.split(","):
                key_value = kvp.split("=")
                clean_key = key_value[0].strip()
                clean_value = key_value[1].strip()
                if len(clean_key) < 1:
                    raise Exception("Empty key")
                if len(clean_value) < 1:
                    raise Exception("Empty value")
                if clean_key in meta:
                    raise Exception("Duplicate metadata key")

                meta[clean_key] = clean_value
    except Exception as ex:
        print(ex)
        raise Exception(f"Error parsing command line metadata: {arg_string}") from ex

    return meta
